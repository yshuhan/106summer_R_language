1 + 3
## [1] 4
9 - 7
## [1] 2
3 * 2
## [1] 6
4 / 2
## [1]2
9 %% 5
## [1]4
1 + 3
## [1] 4
9 - 7
## [1] 2
3 * 2
## [1] 6
4 / 2
## [1]2
9 %% 5
## [1]4
1 + 3
## [1] 4
9 - 7
## [1] 2
3 * 2
## [1] 6
4 / 2
## [1]2
9 %% 5
## [1]4
1 + 3
## [1] 4
9 - 7
## [1] 2
3 * 2
## [1] 6
4 / 2
## [1]2
9 %% 5
## [1]4
1 + 3
9 - 7
3 * 2
4 / 2
9 %% 5
1 + 3
9 - 7
3 * 2
4 / 2
9 %% 5
1.5 + 3
1.5 + "three"
x<-3
q()
help(sum)
x <- 3
y <- 4
z <- sum(x + y)
help(sum)
sqrt(4)
11%/%5
11%%5
<h3>單位：km<sup>2</sup></h3>
help(sub)
log<sub>y</sub>x
log <sub>y</sub>x
help(exp)
c(1,2)+C(1,2,3,4)
c(1, 2) + C(1, 2, 3, 4)
c(1, 2) + C(1, 2)
> c(1, 2) * c(1, 2, 3) # 1*1 2*2 1*3
c(1, 2) * c(1, 2, 3) # 1*1 2*2 1*3
c(1, 2) + c(1, 2) # 1*1 2*2 1*3
c(1, 2) + c(1, 2)
c(1, 2) + c(1, 2)
c(1, 2) + c(1, 2, 3, 4)
c(1, 2) * c(1, 2)
c(1, 2) * c(1, 2, 3, 4)
c(1, 2) * c(1, 2, 3)
$vectors # 特徵向量
vectors # 特徵向量
$values
x <- c(1, 2, 4, 3, 1, 2, 3, 4,1)
factor(x)
x
x <- list(a = 1, b = TRUE, c = "test", d = c(1, 2, 3))
x
x <- list(a = 1, b = TRUE, c = "test", d = c(1, 2, 3))
x[1]
x$b # 是利用 % 加上名稱提取資料
x[[4]][1] # x[[4]] 取出第四個值，因為第四個值是向量，所以可以在取一次指標，取出向量的元素值。
data <- readLines("Desktop/A_lvr_land_A.CSV", encoding="big5") # 讀取實價登入資料，是一行一行讀取進來。
data <- iconv(data, "big5", "utf8") # 將資料轉成 UTF-8。
column_count <- length(strsplit(data[1], ",")[[1]])
row_count <- length(data) # 計算 column 與 count 個數。
fix_data <- matrix(NA, nrow = row_count, ncol = column_count) # 建立一個空的 NA 矩陣，維度來自於 row_count 與 column_count。
for(row in 1:row_count) {
+     for(col in 1:column_count) {
+         fix_data[row,col] <- strsplit(data[row], ",")[[1]][col]}} # 執行 for loop 將資料塞入 fix_data。
write.table(fix_data[2:row_count,], file = "fix_A_lvr_land_A.CSV", sep = ",", col.names = fix_data[1,]) # 將資料輸出，輸出注意一點，因為第一 row 是欄位名稱，所以記得指標要從 2 開始，指標 1 的部分要放到 col.names。
> library(XML) # 要先安裝 XML package 再載入。
library(XML) # 要先安裝 XML package 再載入。
install.packages("XML")
library("XML", lib.loc="~/R/win-library/3.5")
library(XML) # 要先安裝 XML package 再載入。
data <- xmlToDataFrame("Desktop/A_lvr_land_A.XML")
data <- iris # iris 是 R 內建的資料。
write.table(data, file = "test.CSV", sep = ",")
source('pttTestFunction.R')
id = c(1:10)
URL = paste0("https://www.ptt.cc/bbs/Stock/index.html", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
source('pttTestFunction.R')
id = c(1:10)
URL = paste0("https://www.ptt.cc/bbs/Stock/index.html", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
Longley's Economic Regression Data
Longley's Economic Regression Data
longley
library(ggplot2)
longley
ggplot(data = longley, aes(x = Year )) + geom_bar(fill= "lightblue", colour=("black"))
library(ggplot2)
diamonds
ggplot(data = diamonds, aes(x = cut)) + geom_bar(fill= "lightblue", colour=("black"))
longley
ggplot(data = longley, aes(x = GNP.deflator )) + geom_bar(fill= "lightblue", colour=("black"))
longley
ggplot(data = longley, aes(x = Year ,y = GNP.deflator )) + geom_bar(fill= "lightblue", colour=("black"))
mtcars
ggplot(data = , aes(x = hp )) + geom_bar(fill= "lightblue", colour=("black"))
ggplot(data = mtcars, aes(x = hp )) + geom_bar(fill= "lightblue", colour=("black"))
mtcars
ggplot(data = mtcars, aes(x = cyl )) + geom_bar(fill= "lightblue", colour=("black"))
sleep
sleep
ggplot(data = sleep, aes(x = extra )) + geom_bar(fill= "lightblue", colour=("black"))
iris
economics
ggplot(data = economics, aes(x = pce )) + geom_bar(fill= "lightblue", colour=("black"))
ggplot(data = economics, aes(x = psavert )) + geom_bar(fill= "lightblue", colour=("black"))
EuStockMarkets
seals
msleep
ggplot(data = msleep, aes(x = vore )) + geom_bar(fill= "lightblue", colour=("black"))
Titanic
WorldPhones
islands
iris3
trees
stackloss
presidential
seals
ggplot(data = seals, aes(x = lat )) + geom_bar(fill= "lightblue", colour=("black"))
midwest
ggplot(data = midwest, aes(x = state )) + geom_bar(fill= "lightblue", colour=("black"))
movies
iris
ggplot(data = iris, aes(x = Species )) + geom_bar(fill= "lightblue", colour=("black"))
mpg
ggplot(data = mpg, aes(x = manufacturer )) + geom_bar(fill= "lightblue", colour=("black"))
ggplot(data = diamonds, aes(x = price)) +
geom_histogram()
ggplot(data = mpg, aes(x = manufacturer )) + geom_bar(fill= "lightblue", colour=("red"))
ggplot(data = mpg, aes(x = manufacturer )) + geom_bar(fill= "lightblue", colour=("black"))
swiss
npk
euro
attitude
ggplot(data = diamonds, aes(x = table, y=depth)) +
geom_point()
AirPassengers
HairEyeColor
Harman74.cor
ggplot(data = mpg, aes(x = dspl)) +
geom_histogram()
ggplot(data = mpg, aes(x = displ)) +
geom_histogram()
ggplot(data = mpg, aes(x = cty, y=hwy)) +
geom_point()
ggplot(data = mpg, aes(x = displ)) +
geom_histogram(binwidth=2)
ggplot(data = mpg, aes(x = displ)) +
geom_histogram(binwidth=1)
ggplot(data = mpg, aes(x = displ)) +
geom_histogram(binwidth=0.5)
ggplot(data = mpg, aes(x = displ)) +
geom_histogram(binwidth=0.2)
ggplot(data = mpg, aes(x = displ)) +
geom_histogram(binwidth=0.3)
ggplot(data = mpg, aes(x = displ)) +
geom_histogram(binwidth=0.5)
ggplot(data = mpg, aes(x = class, y=hwy)) +
geom_point()
ggplot(data = mpg, aes(x = class, y=hwy)) +
geom_point()
ggplot(data = mpg, aes(x = class, y=hwy,color = class)) +
geom_point()
ggplot(data = mpg, aes(x = cty, y=hwy,color = class)) +
geom_point()
library(ggplot2)
mpg
ggplot(data = mpg, aes(x = manufacturer )) + geom_bar(fill= "lightblue", colour=("black"))
ggplot(data = mpg, aes(x = cty, y=hwy,color = class)) +
geom_point()
library(ggplot2)
mpg
# 汽車廠牌的統計
ggplot(data = mpg, aes(x = manufacturer )) + geom_bar(fill= "lightblue", colour=("black"))
ggplot(data = mpg, aes(x = cty, y=hwy,color = class)) +
geom_point()
ggplot(data = mpg, aes(x =cty, y=hwy,color = class)) +
geom_point()
ggplot(data = mpg, aes(x=cty, y=hwy,color = class)) +
geom_point()
ggplot(mpg, aes(x=class, y = displ)) +
geom_boxplot()
source('pttTestFunction.R')
setwd("D:/github/project/week2")
source('pttTestFunction.R')
install.packages("xml2")
source('pttTestFunction.R')
install.packages("tmcn")
source('pttTestFunction.R')
install.packages("rvest")
source('pttTestFunction.R')
id = c(1:10)
URL = paste0("https://www.ptt.cc/bbs/Stock/index.html", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
pttTestFunction(URL[1], filename[1])
id = c(4354:4454)
URL = paste0("https://www.ptt.cc/bbs/Stock/index.html", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
rm(list=ls(all.names = TRUE))
library(NLP)
install.packages("NLP")
library(NLP)
inlibrary(tm)
library(tm)
install.packages("tm")
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "※")
docs <- tm_map(docs, toSpace, "◆")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs
id = c(249:259)
URL = paste0("https://www.ptt.cc/bbs/money/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "※")
docs <- tm_map(docs, toSpace, "◆")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
seg = lapply(docs, jieba_tokenizer)
library(jiebaR)
library(jiebaRD)
install.packages("jiebaRD")
install.packages("jiebaR")
install.packages("RcolorBrewer")
install.packages("wordcloud")
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "※")
docs <- tm_map(docs, toSpace, "◆")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
docs <- tm_map(docs, toSpace, "推")
docs <- tm_map(docs, toSpace, "了")
docs <- tm_map(docs, toSpace, "就")
docs <- tm_map(docs, toSpace, "在")
docs <- tm_map(docs, toSpace, "有")
docs <- tm_map(docs, toSpace, "也")
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
docs <- tm_map(docs, toSpace, "不")
docs <- tm_map(docs, toSpace, "都")
docs <- tm_map(docs, toSpace, "要")
docs <- tm_map(docs, toSpace, "會")
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
docs <- tm_map(docs, toSpace, "但")
docs <- tm_map(docs, toSpace, "[你]")
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
docs <- tm_map(docs, toSpace, "你")
docs <- tm_map(docs, toSpace, "文章")
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
docs <- tm_map(docs, toSpace, "他")
docs <- tm_map(docs, toSpace, "網址")
docs <- tm_map(docs, toSpace, "轉錄")
docs <- tm_map(docs, toSpace, "嗎")
docs <- tm_map(docs, toSpace, "啊")
docs <- tm_map(docs, toSpace, "啦")
docs <- tm_map(docs, toSpace, "吧")
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
docs <- tm_map(docs, toSpace, "時間")
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
docs <- tm_map(docs, toSpace, "噓")
source('D:/github/project/week2/HW2-2.R', encoding = 'UTF-8', echo=TRUE)
source('D:/github/project/week2/HW2-2-2.R', encoding = 'UTF-8', echo=TRUE)
